# ğŸ§  MCP-HF: Multi-Capability Processor using Hugging Face

## ğŸ“˜ Overview
**MCP-HF** (Multi-Capability Processor using Hugging Face) is a full-stack demo project inspired by [NovaisGabriel/mcp-langchain](https://github.com/NovaisGabriel/mcp-langchain).  
It demonstrates how to build a small modular system capable of analyzing text through multiple NLP tasks â€” all orchestrated by a simple router layer.

The backend (Flask + Hugging Face) automatically decides which task(s) to run â€” summarization, sentiment analysis, or keyword extraction â€” depending on the input text or user-selected mode.  
The frontend (React + Vite) provides a clean UI to input text and view the results.

---

## âš™ï¸ Features
- ğŸ§© **Router Layer**: Automatically routes the request based on text length or explicit mode.
- âœ‚ï¸ **Summarization**: Uses `facebook/bart-large-cnn` to generate concise summaries.
- ğŸ’¬ **Sentiment Analysis**: Uses `distilbert-base-uncased-finetuned-sst-2-english` for polarity detection.
- ğŸª„ **Keyword Extraction**: Uses `KeyBERT` with `sentence-transformers/all-MiniLM-L6-v2` for key terms.
- âš¡ **Modular & Extensible**: Easily plug in other Hugging Face models or tasks.
- ğŸ§ª **Backend Tests**: Includes pytest tests with mocked ML models for fast local testing.

---

## ğŸ§± Project Structure
```
mcp-hf-project/
â”‚
â”œâ”€â”€ backend/                 # Flask API
â”‚   â”œâ”€â”€ app.py               # Main API logic
â”‚   â”œâ”€â”€ requirements.txt     # Dependencies
â”‚   â”œâ”€â”€ tests/               # Unit tests with pytest
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ frontend/                # React + Vite app
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx          # Main component
â”‚   â”‚   â””â”€â”€ main.jsx         # Entry point
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ README.md                # (this file)
```

---

## ğŸš€ Getting Started

### ğŸ§© 1. Backend Setup
```bash
cd backend
python -m venv .venv
.venv\Scripts\activate.ps1
pip install -r requirements.txt
python app.py
```

API will run at: **http://localhost:7860/api/analyze**

### ğŸ§  Example API Request
**POST /api/analyze**
```json
{
  "text": "Artificial intelligence is transforming industries around the world.",
  "mode": "keywords"
}
```

**Response Example**
```json
{
  "decision": "keywords",
  "keywords": ["artificial intelligence", "industries", "transforming"]
}
```

---

### ğŸ’» 2. Frontend Setup
```bash
cd frontend
npm install
npm run dev
```
Then open the Vite dev server (usually [http://localhost:5173](http://localhost:5173)).

Paste some text, choose the mode (`auto`, `summary`, `sentiment`, `keywords`, `all`), and click **Analyze**.

---

## ğŸ§ª 3. Running Tests
All backend tests are located in `backend/tests`.

They mock heavy ML models for quick testing:
```bash
cd backend
pytest -v
```

Expected output:
```
test_api.py::test_analyze_keywords PASSED
test_api.py::test_analyze_summary PASSED
```

---

## âš¡ Customization
You can switch to other Hugging Face models by setting environment variables before running the backend:
```bash
export SUMMARIZER_MODEL="google/pegasus-xsum"
export SENTIMENT_MODEL="nlptown/bert-base-multilingual-uncased-sentiment"
export EMBEDDING_MODEL="sentence-transformers/all-mpnet-base-v2"
```
Then restart the Flask server.

---

## ğŸ§° Tech Stack
**Backend:**
- Flask + Flask-CORS  
- Hugging Face Transformers  
- KeyBERT + Sentence-Transformers  
- Pytest

**Frontend:**
- React + Vite  
- Axios for API calls

---

## ğŸ§© Architecture Summary
The backend mimics a lightweight â€œMCP routerâ€:
1. **Router** inspects text (or explicit mode).
2. Routes to one or more processing â€œcapabilities.â€
3. **Summarizer**, **Sentiment Analyzer**, and **Keyword Extractor** produce results.
4. Combined response is sent to the frontend.

This modularity makes it easy to add new capabilities â€” e.g., translation, entity recognition, or topic classification.

---
